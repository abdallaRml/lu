{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of Copy of Step_4_1_Handling_Categorical_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdallaRml/lu/blob/master/Copy_of_Copy_of_Step_4_1_Handling_Categorical_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5qsJjnj6w9p",
        "colab_type": "text"
      },
      "source": [
        "#*** Fundamentals of Machine Learning***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk2Tfszv5W-w",
        "colab_type": "text"
      },
      "source": [
        "# Scikit-learn: \n",
        "In 2007, David Cournapeau developed Scikit-learn as part of the Google\n",
        "summer of code project. INRIA got involved in 2010 and beta v0.1 was released to the\n",
        "public. Currently, there are more than 700 active contributors, and paid sponsorship from\n",
        "INRIA, Python Software Foundation, Google, and Tinyclues. Many of the functions of Scikitlearn\n",
        "are built upon the SciPy (Scientific Python) library, and it provides a great breadth of\n",
        "efficiently implemented, essential, supervised and unsupervised learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUrmb78l5vur",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning Perspective of Data\n",
        "Data is the facts and figures (can also be referred to as raw data) that we have available\n",
        "with respect to the business context. Data is made up of two aspects:\n",
        "1. Objects such as people, tree, animals, etc.\n",
        "2. Attributes that were recorded for objects such as age, size, weight,\n",
        "cost, etc.\n",
        "\n",
        "At a high level there are two types of variables based on the type of values they\n",
        "can take:\n",
        "1. Continuous quantitative: Variables can take any positive or\n",
        "negative numerical value within a large range. Retail sales amount\n",
        "and insurance claim amount are examples for a continuous\n",
        "variable that can take any number within a large range. These\n",
        "types of variables are also generally called numerical variables.\n",
        "2. Discrete or qualitative: Variables can take only particular values.\n",
        "Retail store location area, state, and city are examples for the\n",
        "discrete variable, as it can take only one particular value for a\n",
        "store (here “store” is our object). These types of variables are also\n",
        "known as categorical variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgJSREhY5zu7",
        "colab_type": "text"
      },
      "source": [
        "Scales of Measurement\n",
        "In general, variables can be measured on four different scales \n",
        "\n",
        "nominal, \n",
        "\n",
        "ordinal, \n",
        "\n",
        "interval,\n",
        "\n",
        "ratio. \n",
        "\n",
        "Mean, median, and mode are the way to understand the central tendency—\n",
        "the middle point—of data distribution. Standard deviation, variance, and range are the\n",
        "most commonly used dispersion measures used to understand the spread of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIvxYpQS4xgW",
        "colab_type": "text"
      },
      "source": [
        "### Handling categorical data\n",
        "\n",
        "Most of the ML libraries are designed to work well with numerical variables. So categorical variables in their original form of text description can’t be directly used for model building. Let’s learn some of the common methods of handling categorical data based on their number of levels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3CwUw_d4xgX",
        "colab_type": "code",
        "outputId": "106b9e92-2c5a-4178-abac-82c90d38af19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import random\n",
        "random.seed(2017)\n",
        "import pandas as pd\n",
        "from patsy import dmatrices\n",
        "\n",
        "df = pd.DataFrame({'A': ['high', 'medium', 'low'],\n",
        "                   'B': [10,20,30]},\n",
        "                    index=[0, 1, 2])\n",
        "                   \n",
        "print(df)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        A   B\n",
            "0    high  10\n",
            "1  medium  20\n",
            "2     low  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTsxYPE387nf",
        "colab_type": "text"
      },
      "source": [
        "Create dummy variable:\n",
        "\n",
        "This is a Boolean variable that indicates the presence of a category with the value 1 and 0 for absence. You should create k-1 dummy variables, where k is the number of level. Scikit-learn provides a useful function, One Hot Encoder, to create a dummy variable for a given categorical variable.\n",
        "\n",
        "Scikit-learn provides a useful function, One Hot Encoder,\n",
        "to create a dummy variable for a given categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwLDf5HM4xgl",
        "colab_type": "code",
        "outputId": "1e23a5ac-8f8c-470e-8ea7-fa356d2e00d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_with_dummies= pd.get_dummies(df, prefix='A', columns=['A'])\n",
        "\n",
        "print(df_with_dummies)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    B  A_high  A_low  A_medium\n",
            "0  10       1      0         0\n",
            "1  20       0      0         1\n",
            "2  30       0      1         0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mT4vpVI4xgq",
        "colab_type": "text"
      },
      "source": [
        "### Convert categories to numeric labels\n",
        "\n",
        "Another simple method is to represent the text description of each level with a number by using ‘Label Encoder’ function of Scikit-learn. If the number of levels are high (example zip code, state etc), then you apply the business logic to combine levels to groups. For example zip code or state can be combined to regions, however in this method there is a risk of losing critical information. Another method is to combine categories based on similar frequency (new category can be high, medium, low).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aNvwP0N4xgq",
        "colab_type": "code",
        "outputId": "4a491f5e-8ceb-43a4-cb31-1e4c04f339aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# using pandas package's factorize function\n",
        "df['A_pd_factorized'] = pd.factorize(df['A'])[0]\n",
        "\n",
        "# Alternatively you can use sklearn package's LabelEncoder function\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "df['A_LabelEncoded'] = le.fit_transform(df.A)\n",
        "print(df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        A   B  A_pd_factorized  A_LabelEncoded\n",
            "0    high  10                0               0\n",
            "1  medium  20                1               2\n",
            "2     low  30                2               1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}