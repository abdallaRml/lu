{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Step_3_1_Scrapping_Beautifulsoup.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gdSrb47dzf7f"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdallaRml/lu/blob/master/Copy_of_Step_3_1_Scrapping_Beautifulsoup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PExwqz59zbZD",
        "colab_type": "text"
      },
      "source": [
        "INTRO\n",
        "\n",
        "copy this file into your google drive, how:\n",
        "\n",
        "Click File in the left hand corner, then select \"save a copy in drive.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSrb47dzf7f",
        "colab_type": "text"
      },
      "source": [
        "# Install dan Import Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQou0RAqIwO6",
        "colab_type": "text"
      },
      "source": [
        "**Instal library requests**\n",
        "\n",
        "Ref: https://pypi.org/project/requests/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24HWXGaU-LF1",
        "colab_type": "code",
        "outputId": "766dac9e-7257-4510-8d24-e8a37e122a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCsUz0gd0Uwf",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Install library Beautifulsoup\n",
        "\n",
        "Ref: https://pypi.org/project/beautifulsoup4/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZFuDAkK-PYR",
        "colab_type": "code",
        "outputId": "ed697e73-16b9-4524-d11e-bcffb97aad59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install beautifulsoup4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOacKxNvInDY",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "Kemudian import semua library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omaB3yhBzMq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests     # library untuk URL\n",
        "from bs4 import BeautifulSoup   # library untuk scrapping web\n",
        "from csv import writer    # library untuk membuat file CSV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyCkneN34a11",
        "colab_type": "text"
      },
      "source": [
        "# Using Beautifulsoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAIVpAVP3ng7",
        "colab_type": "text"
      },
      "source": [
        "Before implementing BeautifulSoup with collabs, do the following:\n",
        "1. Enter the URL (website address) of the destination in a new tab\n",
        "2. Press F12 or right-click Inspect\n",
        "3. Look for the id or class name needed (in the \"body\" tag)\n",
        "4. Pay attention to the parent and child of the existing class\n",
        "\n",
        "Ref: https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html#quick-start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzoNC1Bj1JzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.tribunnews.com/techno\" # initializing the URL address\n",
        "res = requests.get(url)     # use the request library by sending a header\n",
        "html = BeautifulSoup(res.content, \"html.parser\")   # parsing html using Beautifulsoup\n",
        "rows = html.find(\"div\", class_ = \"bsh ovh \")     # use the find function to find a class named \"_1E0nAqju\"\n",
        "# look for all classes with the name \"I8luE9wS\" in the variable rows\n",
        "divs = rows.findAll(\"li\", {\"class\" :\"p1520 art-list pos_rel\"})   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXnLHILB4lRv",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Creating CSV files**\n",
        "\n",
        "Ref:\n",
        "\n",
        "create csv = https://docs.python.org/3/library/csv.html\n",
        "\n",
        "File handling = https://stackabuse.com/file-handling-in-python/\n",
        "\n",
        "---\n",
        "Save the folder path in the collabs, look at the left sidebar. click on the folder tab\n",
        "\n",
        "path: / content / sample_data / NAME_FILE\n",
        "\n",
        "Get data in the form of:\n",
        "\n",
        "* Category\n",
        "*   News content\n",
        "* Link\n",
        "\n",
        "\n",
        "**Note** : To see the results must be refreshed in the sample_data folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFm7KfGA1Otp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "593df9cc-57ee-4da5-a104-5a140b6de2f0"
      },
      "source": [
        "with open('/content/sample_data/berita_tribun1.csv', 'w') as csv_file:\n",
        "    csv_writer = writer(csv_file)\n",
        "    # initialize column names for CSV files\n",
        "    headers = ['Category', 'News Content', 'Link']\n",
        "    # creates a header in the csv file\n",
        "    csv_writer.writerow(headers)\n",
        "\n",
        "    # loop variable div (is an html tag <li>)\n",
        "    for div in divs:\n",
        "      # looks for the <span> tag and replaces the blank or enter line\n",
        "        category = div.find(\"div\", class_ = \"mr140\").span.get_text().replace('\\n', '')    \n",
        "        # searches <h3> and replaces spaces\n",
        "        title = div.find(\"div\", class_ = \"mr140\").h3.get_text().replace('\\t', '')     \n",
        "        # looking for tag <a><href>s\n",
        "        link = div.find(\"div\", class_ = \"mr140\").h3.a.get(\"href\")   \n",
        "        # make a column of data rows in CSV with variables (category, title, link)\n",
        "        csv_writer.writerow([category, title, link])      \n",
        "      "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7339ad77bdf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdivs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;31m# looks for the <span> tag and replaces the blank or enter line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mr140\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# searches <h3> and replaces spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mr140\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'span'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogN7W8ph6XT0",
        "colab_type": "text"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbWVYLE76X02",
        "colab_type": "text"
      },
      "source": [
        "# Nouvelle section"
      ]
    }
  ]
}